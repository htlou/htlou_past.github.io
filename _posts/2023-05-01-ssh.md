---
layout: article
title: 集群教程：我的被坑经验
mathjax: true
tags: tutorial
---





**0.0 一些有用的东西和一些废话**（这好像也是一句废话诶）

0.0.1 本文仅代表一种可行的解法，因此可能（在某些我没有注意到的地方）有些繁琐，且全教程完全基于命令行，当然存在使用vscode或者pycharm之类的方法，但是我受够了在某些地方突然被背刺一下了，所以果断选择命令行（终端）

0.0.2 我会慢慢把一些周围的东西整合进去，使这个教程包含一些vim和linux的基本知识，当然也可以有不会的问chatGPT ，祂比我聪明/doge

0.0.3 代码里的汉字是要根据情况被替换的内容，一般情况下全程不会涉及中文

0.0.4 我在自己摸索的时候用到的一些东西：

&emsp;[朱毅鑫老师的使用手册](https://pku-core.feishu.cn/docx/KZerdFIcQoESlexvY5XcpdtgnBd)(密码班级群发过)

&emsp;[etc]()

**1.0 登录集群**

首先，集群需要录入公钥进行注册。下面介绍一个（最简单的）生成公钥的方法：

打开命令行，输入
~~~
ssh-keygen
~~~

接下去会要求确定生成的地址和passphrase，简单起见仅使用默认地址和空passphrase，因此都回车跳过。

在此过程中，会出现一行类似如下的文字：
~~~
Enter file in which to save the key (/ceph/home/louhantao/.ssh/id_rsa)
~~~
复制括号内的内容，比如此处复制到 `/ceph/home/louhantao/.ssh/` ，它就是存储公钥的地址

通过文件系统打开，找到上述过程中生成的以pub结尾的文件，用记事本/文本编辑器/vim打开，复制其中的内容，你就得到了电脑的公钥。按照要求将其填入问卷，等待录入完成。

在这之后，你可以直接在命令行中使用如下命令登入集群：

~~~
ssh -p 19922 你的姓名小写全拼@117.139.124.77
~~~

补充一个可以让登陆方便一点的方法：用随便什么编辑器打开~/.ssh/config，添加如下文本：

~~~
Host (你可以起个名字，我用的是Tong_ai)
  HostName 117.139.124.77
  Port 19922
  User 你的姓名小写全拼
~~~

然后你就可以直接用 `ssh 你起的名字` 登录啦！

**1 安装anaconda并配置环境变量**

1.1 下载并安装anaconda

从[anaconda官网](https://www.anaconda.com/download#downloads)获取下载链接，wget下载到你的目录（随着时间推移这个包可能会有新版本）：

~~~
wget https://repo.anaconda.com/archive/Anaconda3-2023.03-1-Linux-x86_64.sh
~~~

<blockquote>
服务器网速挺慢的...没啥办法（（（
</blockquote>
下载完成后用bash命令安装：

~~~
bash Anaconda3-2023.03-1-Linux-x86_64.sh
~~~
狂按空格键跳过那些声明，问Do you accept就输入yes回车，在`>>>`的时候也直接敲回车，等待安装完成

1.2 一些前置性操作

等待安装完成时可以先做一些必要的前置工作：

添加bash启动项使得bash能够在开机时自启动配置环境变量[1]

开始上传本地代码文件[2]

1.3 将conda的环境变量载入bash

安装完成后，执行命令：
~~~
eval "$(/ceph/home/姓名全拼/anaconda3/bin/conda shell.bash hook)"
~~~

执行完毕后命令行头应当出现一个(base)，说明安装完成

随后运行`conda init`将环境变量载入.bashrc中.运行完成后依次执行`exit` `logout`退出并重新登录，此时命令行头应当出现一个(base)完成conda配置

**2 虚拟环境建立和包安装** <small>有安装cuda经验的话安装cuda torch后跳过此节即可</small>

2.1 虚拟环境建立

执行 `conda create --name cuda_torch python=3.10` 新建一个cuda_torch环境（名字可以自己改但我不推荐不新建环境直接在base装库）

2.2 cuda安装

实验证明cuda是不用安装的...

直接运行 `module load cudnn8.5-cuda11.7/8.5.0.96` 即可进入对应环境

实在要装的话参考注释[3]

2.3 依赖cuda的相关包安装

先进入一个有显卡的环境（没有似乎也行？），然后执行：
~~~
module load slurm
srun --partition=IAI_SLURM_3090 --nodes 1 --gres=gpu:1 --cpus-per-task=10 --qos=debug --time 1:00:00 --comment="demo" --pty bash
conda install pytorch torchvision torchaudio pytorch-cuda=11.7 -c pytorch -c nvidia
~~~
会花费比较长的时间

2.4 安装剩下的包

conda自行安装

2.5 一个小技巧

可以写一个start.sh脚本，内容如下：
~~~
#!/bin/bash

source ~/.bashrc

conda activate cuda_torch

module load slurm

module load cudnn8.5-cuda11.7/8.5.0.96

echo  "Initialized done"
~~~
然后将`.bash_profile`中的内容改为`source ~/.start.sh`
就可以在登入的时候一键初始化了


**3 脚本与运行**

3.1 普通脚本

事实上2.5中展示的就是一个脚本，通过bash sh source命令执行的，具体问chatgpt

3.2 运行脚本

在集群中，长时间运行任务需要写脚本运行，先在对应目录里 `vim run.sh` 新建一个脚本文件，按i进入编辑模式，然后输入脚本内容。

常见的运行脚本结构如下：
~~~
#! /bin/bash

#SBATCH --partition=IAI_SLURM_3090
#SBATCH --job-name=sbatch_example
#SBATCH --ntasks=1
#SBATCH --gres=gpu:1
#SBATCH --qos=singlegpu
#SBATCH --cpus-per-task=10
#SBATCH --time 8:00:00

cd /ceph/home/待执行文件的上一级目录
python -u main.py
~~~
-u代表直接输出，不经过缓存

然后按esc退出编辑模式，输入 `:wq` 保存并退出，输入：
~~~
module load slurm
sbatch run.sh
~~~

就可以运行了，随后在同一级目录下会看到形如slurm-xxxx.out的输出文件，就是对应jobid的输出

(note: squeue和scancel朱老师的教程里有就不赘述了)

3.3 输出

<blockquote>
提交后，就可以输入`squeue`看到job处于正在运行的状态，同时，你的目录下会出现一个`slurm-{jobid}.out`的文件，记录了`stdout`的输出信息。——朱老师的文档
</blockquote>









注
---

[1] 具体操作：另开一个终端，登入后执行
~~~
vim .bash_profile
~~~
这将会打开vim编辑的bash_profile界面
按i进入编辑模式，输入：
~~~
source ~/.bashrc
~~~
按esc退出编辑模式，然后直接输入
~~~
:wq
~~~
保存并退出vim，回到主界面，运行一下
~~~
bash
which bash
~~~
应当显示/usr/bin/bash. 

[2] 关于本地的代码和数据文件，有几种传输方式，在 [朱毅鑫老师的使用手册](https://pku-core.feishu.cn/docx/KZerdFIcQoESlexvY5XcpdtgnBd) 里简单列了一下：
<blockquote>

1.  `scp`/`rsync`推荐使用后者
    
2.  Dropbox/[阿里云盘](https://github.com/tickstep/aliyunpan)等
    
3.  Amazon S3/腾讯云、阿里云对象存储

</blockquote>

根据使用经验，传一般文件用rsync会比较方便，大文件用[阿里云盘](https://github.com/tickstep/aliyunpan)会好一点，后者链接里有详细介绍就不抄了

关于rsync:

rsync 是一个常用的 Linux 命令行工具，用于在本地和远程系统之间同步文件和目录。它可以使用 SSH 或 RSH 等协议进行安全的数据传输，并提供了许多可选的参数和功能，使其非常灵活和强大。

下面是一些常用的 rsync 命令和选项：

1.  同步本地目录到远程服务器：

```
rsync -avz /path/to/local/dir user@remote:/path/to/remote/dir
```

这条命令将同步本地目录  `/path/to/local/dir`  到远程服务器的  `/path/to/remote/dir`  目录。其中  `-a`  表示归档模式，将保留所有文件属性和权限；`-v`  表示详细输出，将显示传输进度和文件列表；`-z`  表示压缩传输，可以加快传输速度。

2.  同步远程服务器目录到本地：
```
rsync -avz -e 'ssh -p 19922' user@remote:/path/to/remote/dir /path/to/local/dir
```

这条命令将同步远程服务器的  `/path/to/remote/dir`  目录到本地的  `/path/to/local/dir`  目录。

3.  远程同步并保留删除文件：
```
rsync -avz -e 'ssh -p 19922' --delete user@remote:/path/to/remote/dir /path/to/local/dir
```

这条命令将同步远程服务器的  `/path/to/remote/dir`  目录到本地的  `/path/to/local/dir`  目录，并删除本地目录中不存在的远程文件。

4.  同步时排除指定文件或目录：
```
rsync -avz --exclude 'file.txt' /path/to/local/dir user@remote:/path/to/remote/dir
```

这条命令将同步本地目录  `/path/to/local/dir`  到远程服务器的  `/path/to/remote/dir`  目录，但排除了名为  `file.txt`  的文件。您可以指定多个排除模式，例如  `--exclude 'dir/' --exclude '*.log'`。


这里只是列举了一些 rsync 常用的命令和选项，rsync 提供了更多的功能和选项，您可以通过  `man rsync`  命令查看详细文档。

[3] 在[英伟达官网](https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&Distribution=Rocky&target_version=8&target_type=runfile_local)找到对应rocky linux 8(x86_64)的runfile安装方式（没有sudo权限所以不能直接rpm）：
~~~
```
wget https://developer.download.nvidia.com/compute/cuda/12.1.1/local_installers/cuda_12.1.1_530.30.02_linux.run
```
~~~
然后先进入一个有显卡的环境，赋予该文件可执行权限再运行这个文件：
~~~
module load slurm
srun --partition=IAI_SLURM_3090 --nodes 1 --gres=gpu:1 --cpus-per-task=10 --qos=debug --time 1:00:00 --comment="demo" --pty bash
chmod +x cuda_12.1.1_530.30.02_linux.run
sh cuda_12.1.1_530.30.02_linux.run
~~~

在随后跳出的选区中选择accept，然后用方向键和回车进入option选项卡中的 `Library install path` ，在路径上填入 `/ceph/home/姓名全拼` 后选择done回到主安装页面

安装包中选择`CUDA toolkit`  `CUDA documentation`，并在toolkit处输入A进入详细一栏，安装路径前加上`/ceph/home/姓名全拼`，之后选择install开始安装
